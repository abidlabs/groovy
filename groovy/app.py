import gradio as gr
from PIL.Image import Image


def create_app(self, inputs, prompt, streamer, run_immediately):
    with gr.Blocks(theme=gr.themes.Base()) as app:
        for input in inputs:
            input.render()

        with gr.Row():
            prompt_box = gr.Textbox(label="Prompt", value=prompt, show_label=False)
            run_button = gr.Button("Run", variant="primary")
            stop_button = gr.Button("Stop", variant="stop", visible=False)

        chat_log = gr.Chatbot(
            label="Log",
            type="messages",
            group_consecutive_messages=False,
            visible=False,
        )

        @gr.on(
            triggers=[app.load] + [input.change for input in inputs],
            inputs=inputs,
            outputs=[prompt_box],
            trigger_mode="always_last",
        )
        def construct_prompt(*input_values):
            return prompt.format(*input_values)

        run_triggers = [run_button.click]
        if run_immediately:
            run_triggers.append(app.load)

        @gr.on(
            triggers=run_triggers,
            inputs=[prompt_box],
            outputs=[run_button, stop_button, chat_log],
        )
        def run_flow(prompt):
            yield {
                run_button: gr.Button(visible=False), 
                chat_log: gr.Chatbot(visible=True),
                stop_button: gr.Button(visible=True)
            }

            log = [gr.ChatMessage(content=prompt, role="user")]
            yield {chat_log: log}

            for step in streamer(prompt):
                if isinstance(step, str):
                    log.append(gr.ChatMessage(content=step, role="assistant"))
                elif isinstance(step, Image):
                    log.append(gr.ChatMessage(content=gr.Image(step), role="assistant"))
                elif isinstance(step, gr.ChatMessage):
                    log.append(step)
                else:
                    raise ValueError(
                        f"Cannot handle type: {type(step)} generated by streamer function."
                    )
                yield {chat_log: log}

    return app
